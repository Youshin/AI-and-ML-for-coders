{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/pIjCDMvPdS8go7j/XEPC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Youshin/AI-and-ML-for-coders/blob/main/2%EC%9E%A5_%EC%BB%B4%ED%93%A8%ED%84%B0_%EB%B9%84%EC%A0%84_%EC%86%8C%EA%B0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST - 0에서 9까지 손으로 쓴 7만개의 숫자 이미지로 이루어진 데이터 셋"
      ],
      "metadata": {
        "id": "H7rPZheub1_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 신경망 설계"
      ],
      "metadata": {
        "id": "va6-ECZwczB0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0YW4FLpboFl",
        "outputId": "651db19e-64b4-4276-cc01-69a6de4c9fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.5032 - accuracy: 0.8245\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3762 - accuracy: 0.8643\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3377 - accuracy: 0.8769\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3132 - accuracy: 0.8839\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2954 - accuracy: 0.8909\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81c1b56fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "data = tf.keras.datasets.fashion_mnist # 이미지 데이터셋 가져오기.\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = data.load_data() # 가져온 데이터 훈련/테스트 세트로 나누기\n",
        "\n",
        "# 이미지 픽셀이 모두 흑백이므로 0에서 255 사잇값을 가지는데, 255로 나누게 되면 픽셀을 0에서 1사이의 값으로 나타낼 수 있습니다. - 정규화normalization\n",
        "# 텐서플로에서 신경망을 훈련할 떄 정규화가 성능을 높인다는 것을 기억하라(https://developers.google.com/machine-learning/data-prep/transform/normalization) - 왜? (https://coresignal.com/blog/data-normalization/)\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = Sequential([\n",
        "    # 뉴런의 층이 아니라 입력을 위한 크기를 지정합니다. 28 x 28, 패션 MNIST의 이미지 크기. 2D배열인 행렬을 1D 배열인 벡터로 변환합니다.\n",
        "    Flatten(input_shape=(28, 28)), \n",
        "    # 뉴런 128개를 지정(임의의 숫자)했습니다. (은닉 층, 입력과 출력 사이에 위치해 밖에서는 보이지 않으므로 은닉되었다고 말함)\n",
        "    # 과대적합overfitting이 되거나 학습에 필요한 파라미터가 부족할 수 있으므로 적절한 뉴런 갯수를 선정해야함.\n",
        "    # 활성화 함수의 경우 층의 각 뉴런에 적용되는 함수입니다. ReLU(rectified linear unit) = 0보다 큰 값을 반환하는 함수. 다음층의 계산에 음숫값을 전달하고 싶지 않으므로 ReLU 활성화 함수를 사용\n",
        "    Dense(128, activation=tf.nn.relu),\n",
        "    # 출력층이라 합니다. 옷의 클래스가 10개이므로 10개의 뉴런을 둡니다.\n",
        "    # softmax 함수는 출력 층의 뉴런에서 출력된 값의 합이 1이 되도록 만듭니다. - 확률처럼 이해하기 좋게 만듭니다.\n",
        "    Dense(10, activation=tf.nn.softmax) \n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    # adam 옵티마이저는 sgd 옵티마이저의 진화된 것으로 더 빠르고 효율적이라고 알려져 있습니다.\n",
        "    optimizer='adam',\n",
        "    # 희소한 범주형 크로스 엔트로피. 손실 함수. one-hot encoding된 레이블의 경우 categorical_crossentropy 손실 함수를 사용합니다.\n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 평가하는 작업. 테스트를 위해 준비한 1만 개의 이미지와 레이블을 훈련된 모델에 전달해 각 이미지의 출력을 얻고 실제 레이블과 비교하여 결과를 확인합니다.\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNZ1kNGicue6",
        "outputId": "29a219e1-0852-4aa3-d554-074b37e0b0bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3659 - accuracy: 0.8648\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36590391397476196, 0.864799976348877]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGW6Epulgd8y",
        "outputId": "01ac83c4-0de3-4859-c552-a6cf2c512557"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "[1.5702317e-04 1.2069041e-08 1.8964449e-06 1.7673253e-06 5.5245960e-06\n",
            " 5.4413062e-03 3.0617488e-05 8.7174386e-02 1.1436770e-04 9.0707296e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "배열을 살펴보면 다른 값들은 매우 작고 마지막 값인 배열 인덱스 9가 가장 크다는 것을 확인 할 수 있습니다.\n",
        "이 값은 이미지가 특정 인덱스의 레이블에 매칭될 확률입니다.\n",
        "\n",
        "따라서 이 신경망은 인덱스 0에 있는 의류 아이템이 90.7%의 확률로 레이블9라고 출력한 것입니다."
      ],
      "metadata": {
        "id": "bYTvNSl-hIYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 더 오래 훈련하기: 과대적합"
      ],
      "metadata": {
        "id": "nMtASWBkhdjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), \n",
        "    Dense(128, activation=tf.nn.relu),\n",
        "    Dense(10, activation=tf.nn.softmax) \n",
        "])\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.fit(train_images, train_labels, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAdKZprBg-Wx",
        "outputId": "c9437e86-a6ea-43cd-dbc7-d58a53f3a233"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4979 - accuracy: 0.8232\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3729 - accuracy: 0.8648\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3337 - accuracy: 0.8788\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3123 - accuracy: 0.8857\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2946 - accuracy: 0.8919\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2799 - accuracy: 0.8965\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2664 - accuracy: 0.9007\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2556 - accuracy: 0.9050\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2481 - accuracy: 0.9087\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2384 - accuracy: 0.9114\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2309 - accuracy: 0.9144\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2236 - accuracy: 0.9157\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2159 - accuracy: 0.9195\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2115 - accuracy: 0.9209\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2053 - accuracy: 0.9224\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1982 - accuracy: 0.9255\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1945 - accuracy: 0.9270\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1901 - accuracy: 0.9281\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1833 - accuracy: 0.9312\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1792 - accuracy: 0.9319\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1754 - accuracy: 0.9338\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1707 - accuracy: 0.9355\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1671 - accuracy: 0.9370\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1629 - accuracy: 0.9384\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1592 - accuracy: 0.9407\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1585 - accuracy: 0.9402\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1536 - accuracy: 0.9420\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1490 - accuracy: 0.9439\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1477 - accuracy: 0.9449\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1435 - accuracy: 0.9454\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1394 - accuracy: 0.9477\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1371 - accuracy: 0.9492\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1356 - accuracy: 0.9488\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1327 - accuracy: 0.9492\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1308 - accuracy: 0.9512\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1272 - accuracy: 0.9517\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1257 - accuracy: 0.9538\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1219 - accuracy: 0.9541\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1182 - accuracy: 0.9556\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1165 - accuracy: 0.9563\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1182 - accuracy: 0.9557\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1135 - accuracy: 0.9577\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1118 - accuracy: 0.9576\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1093 - accuracy: 0.9588\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1073 - accuracy: 0.9590\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1053 - accuracy: 0.9600\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1068 - accuracy: 0.9601\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1017 - accuracy: 0.9616\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1020 - accuracy: 0.9625\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0983 - accuracy: 0.9629\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81c1a0e700>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v2tm8YShhM1",
        "outputId": "2afbb6c0-4687-494d-e3ec-66f5bbf52e4f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4937 - accuracy: 0.8925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4937026798725128, 0.8924999833106995]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련세트의 정확도에 비해 검증의 성능이 오르지 않았습니다.\n",
        "검증세트에 비해 훈련세트에 특화되었음을 보여줍니다. 이를 **과대적합**이라고 부릅니다"
      ],
      "metadata": {
        "id": "1lux11tti4rX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') > 0.95):\n",
        "      print(\"\\n정확도 95%에 도달하여 훈련을 멈춥니다!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=50, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ZZYk8uiw_w",
        "outputId": "9b6c5b2e-66c3-46df-b415-2a689066125b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9631\n",
            "정확도 95%에 도달하여 훈련을 멈춥니다!\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0977 - accuracy: 0.9631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81c233d6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "비전 작업을 더 잘 수행하려면 컴퓨터가 원본 픽셀 대신에 이미지의 특징을 학습해야 합니다.\n",
        "이때 합성곱convolution을 사용하면 앞서 이 작업을 수행할 수 있습니다."
      ],
      "metadata": {
        "id": "6nqDZC0jk0DV"
      }
    }
  ]
}